{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f448925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from dateutil import parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "420065e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#For Desktop \n",
    "#s.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "#For Desktop\n",
    "#login(token=os.getenv(\"HF_MASTER_KEY\"))\n",
    "\n",
    "#For Macbook\n",
    "load_dotenv()\n",
    "login(token=os.getenv(\"MACBOOK_HF_KEY\"))\n",
    "\n",
    "# Clear conflicting environment variables\n",
    "#if 'PYTHONPATH' in os.environ:\n",
    "    #del os.environ['PYTHONPATH']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0849b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/07/02 14:39:23 WARN Utils: Your hostname, MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 10.42.73.3 instead (on interface en0)\n",
      "25/07/02 14:39:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/07/02 14:39:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/02 14:39:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Test run with Reuters and Ashraq financial news dataset\n",
    "reuters_spark = SparkSession.builder.appName(\"ReutersNews\").getOrCreate()\n",
    "finnews_spark = SparkSession.builder.appName('FinNews').getOrCreate()\n",
    "\n",
    "# Dictionary mapping spark sessions to dataset names\n",
    "spark_dataset_mapping = {\n",
    "    reuters_spark: \"danidanou/Reuters_Financial_News\",\n",
    "    finnews_spark: \"ashraq/financial-news-articles\"\n",
    "}\n",
    "\n",
    "def ds_to_spark(spark_session, dataset_name, dataset_size=10000):\n",
    "    \"\"\"\n",
    "    Convert a HuggingFace dataset to a Spark DataFrame\n",
    "    \n",
    "    Args:\n",
    "        spark_session: Active Spark session\n",
    "        dataset_name: HuggingFace dataset name/path\n",
    "        dataset_size: Number of rows to load (default: 10000)\n",
    "    \n",
    "    Returns:\n",
    "        Spark DataFrame or None if failed\n",
    "    \"\"\"\n",
    "    from pyspark.sql.types import StructType, StructField, StringType\n",
    "    \n",
    "    print(f\"Loading dataset: {dataset_name}\")\n",
    "    \n",
    "    try:\n",
    "        # Load HuggingFace dataset with size limit\n",
    "        hf_df = load_dataset(dataset_name, split=f'train[:{dataset_size}]')\n",
    "        \n",
    "        # Convert to pandas\n",
    "        pd_df = hf_df.to_pandas()\n",
    "        \n",
    "        print(f\"DF shape: {pd_df.shape}\")\n",
    "        \n",
    "        # Check and clean columns\n",
    "        for col in pd_df.columns:\n",
    "            if pd_df[col].dtype == 'object':\n",
    "                # Get a sample of non-null values\n",
    "                non_null_values = pd_df[col].dropna()\n",
    "                \n",
    "                if len(non_null_values) > 0:\n",
    "                    # Check the first few values to determine type\n",
    "                    sample_value = non_null_values.iloc[0]\n",
    "                    \n",
    "                    if isinstance(sample_value, (list, dict)):\n",
    "                        # Convert complex types to string\n",
    "                        pd_df[col] = pd_df[col].apply(lambda x: str(x) if x is not None else \"\")\n",
    "                        print(f\"Converted col '{col}' to string\")\n",
    "        \n",
    "        # Fill null values\n",
    "        pd_df = pd_df.fillna(\"\")\n",
    "        \n",
    "        try:\n",
    "            # Convert pandas DataFrame to list of Row objects for compatibility\n",
    "            records = pd_df.to_dict('records')\n",
    "            spark_df = spark_session.createDataFrame(records)\n",
    "            print(f\"Successfully created Spark DataFrame for {dataset_name}\")\n",
    "            print(\"Schema:\")\n",
    "            spark_df.printSchema()\n",
    "            return spark_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error creating DataFrame for {dataset_name}: {e}\")\n",
    "            \n",
    "            # Alternative approach: Define explicit schema and use records\n",
    "            print(\"Trying with explicit string schema and records conversion...\")\n",
    "            \n",
    "            try:\n",
    "                # Create schema with all string types\n",
    "                string_schema = StructType([\n",
    "                    StructField(col, StringType(), True) for col in pd_df.columns\n",
    "                ])\n",
    "                \n",
    "                # Convert all columns to string\n",
    "                pd_df_str = pd_df.astype(str)\n",
    "                \n",
    "                # Convert to records format\n",
    "                records = pd_df_str.to_dict('records')\n",
    "                \n",
    "                # Create Spark DataFrame with explicit schema\n",
    "                spark_df = spark_session.createDataFrame(records, schema=string_schema)\n",
    "                print(f\"Successfully created Spark DataFrame with string schema for {dataset_name}\")\n",
    "                print(\"Schema:\")\n",
    "                spark_df.printSchema()\n",
    "                return spark_df\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"Failed even with string schema and records: {e2}\")\n",
    "                \n",
    "                # Last resort: Manual row creation\n",
    "                print(\"Trying manual row creation...\")\n",
    "                try:\n",
    "                    from pyspark.sql import Row\n",
    "                    \n",
    "                    # Create Row objects manually\n",
    "                    Row = Row(*pd_df.columns)\n",
    "                    rows = [Row(*[str(val) for val in row]) for row in pd_df.values]\n",
    "                    \n",
    "                    spark_df = spark_session.createDataFrame(rows)\n",
    "                    print(f\"Successfully created Spark DataFrame with manual row creation for {dataset_name}\")\n",
    "                    print(\"Schema:\")\n",
    "                    spark_df.printSchema()\n",
    "                    return spark_df\n",
    "                    \n",
    "                except Exception as e3:\n",
    "                    print(f\"All methods failed for {dataset_name}: {e3}\")\n",
    "                    return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset {dataset_name}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694ee32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 411547 entries, 0 to 411600\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   title   411547 non-null  object\n",
      " 1   Date    105359 non-null  object\n",
      " 2   url     411547 non-null  object\n",
      " 3   text    411547 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 15.7+ MB\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "reuters_df = load_dataset(\"danidanou/Reuters_Financial_News\")['train'].to_pandas()\n",
    "finnews_df = load_dataset(\"ashraq/financial-news-articles\")['train'].to_pandas()\n",
    "\n",
    "reuters_df = reuters_df.rename(columns={\n",
    "    'Article': 'text',\n",
    "    'Link': 'url',\n",
    "    'Headline': 'title'\n",
    "    })\n",
    "\n",
    "reuters_df = reuters_df.drop(columns=['Journalists', '__index_level_0__', 'Summary'])\n",
    "\n",
    "#Merging the df\n",
    "merged_df = pd.concat([reuters_df, finnews_df])\n",
    "\n",
    "#Shuffling the rows\n",
    "merged_df = merged_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#Removing duplicates based on url\n",
    "merged_df = merged_df.drop_duplicates(subset=['url'], keep='first')\n",
    "\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98a03a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianzuniga/Library/Python/3.10/lib/python/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n",
      "/Users/cristianzuniga/Library/Python/3.10/lib/python/site-packages/dateutil/parser/_parser.py:1207: UnknownTimezoneWarning: tzname EST identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Date</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>news_medium</th>\n",
       "      <th>news_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commentary: To contain Iran, look first to Yem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reuters.com/article/us-pascual-yem...</td>\n",
       "      <td>In the Middle East, all eyes are fixed on Syri...</td>\n",
       "      <td>6646</td>\n",
       "      <td>reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HYPR Expands to Europe as Growing Demand for P...</td>\n",
       "      <td>2018-05-21</td>\n",
       "      <td>http://www.cnbc.com/2018/05/21/pr-newswire-hyp...</td>\n",
       "      <td>NEW YORK, May 21, 2018 /PRNewswire/ -- HYPR Co...</td>\n",
       "      <td>5496</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don’t Get Distracted by the Trade Deficit With...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.wsj.com/articles/dont-get-distract...</td>\n",
       "      <td>Trade negotiations with China are grinding for...</td>\n",
       "      <td>582</td>\n",
       "      <td>wsj</td>\n",
       "      <td>articles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GSK buys out Novartis in $13bln shake-up</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>https://www.reuters.com/video/2018/03/27/gsk-b...</td>\n",
       "      <td>GSK buys out Novartis in $13bln shake-up 8:48a...</td>\n",
       "      <td>534</td>\n",
       "      <td>reuters</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CORRECTED-US STOCKS SNAPSHOT-Wall St briefly l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reuters.com/article/usa-stocks/us-...</td>\n",
       "      <td>April 18, 2018 / 6:20 PM / Updated 18 minutes ...</td>\n",
       "      <td>849</td>\n",
       "      <td>reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411596</th>\n",
       "      <td>Fed's Bullard: May see asset sales late 2010</td>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>http://www.reuters.com/article/2010/02/08/us-u...</td>\n",
       "      <td>The Fed's purchases last year of longer-term ...</td>\n",
       "      <td>4535</td>\n",
       "      <td>reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411597</th>\n",
       "      <td>SocGen suicides put stress at work under spotl...</td>\n",
       "      <td>2008-01-29</td>\n",
       "      <td>http://www.reuters.com/article/2008/01/29/us-s...</td>\n",
       "      <td>Societe Generale last week revealed that a ro...</td>\n",
       "      <td>3151</td>\n",
       "      <td>reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411598</th>\n",
       "      <td>Royal Mail nine-month revenue rises on higher ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://uk.reuters.com/article/uk-royal-mail-o...</td>\n",
       "      <td>January 18, 2018 / 7:30 AM / Updated 12 hours ...</td>\n",
       "      <td>1401</td>\n",
       "      <td>uk.reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411599</th>\n",
       "      <td>China is a target market for Scotch Whisky</td>\n",
       "      <td>2018-01-31</td>\n",
       "      <td>https://www.cnbc.com/video/2018/01/31/china-is...</td>\n",
       "      <td>China is a target market for Scotch Whisky 20 ...</td>\n",
       "      <td>193</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411600</th>\n",
       "      <td>BRIEF-Humana Reports Qtrly EPS Of $1.29 ‍​</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reuters.com/article/brief-humana-r...</td>\n",
       "      <td>46 AM / in 12 minutes BRIEF-Humana Reports Qt...</td>\n",
       "      <td>1673</td>\n",
       "      <td>reuters</td>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411547 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title        Date  \\\n",
       "0       Commentary: To contain Iran, look first to Yem...         NaN   \n",
       "1       HYPR Expands to Europe as Growing Demand for P...  2018-05-21   \n",
       "2       Don’t Get Distracted by the Trade Deficit With...         NaN   \n",
       "3                GSK buys out Novartis in $13bln shake-up  2018-03-27   \n",
       "4       CORRECTED-US STOCKS SNAPSHOT-Wall St briefly l...         NaN   \n",
       "...                                                   ...         ...   \n",
       "411596       Fed's Bullard: May see asset sales late 2010  2010-02-08   \n",
       "411597  SocGen suicides put stress at work under spotl...  2008-01-29   \n",
       "411598  Royal Mail nine-month revenue rises on higher ...         NaN   \n",
       "411599         China is a target market for Scotch Whisky  2018-01-31   \n",
       "411600         BRIEF-Humana Reports Qtrly EPS Of $1.29 ‍​         NaN   \n",
       "\n",
       "                                                      url  \\\n",
       "0       https://www.reuters.com/article/us-pascual-yem...   \n",
       "1       http://www.cnbc.com/2018/05/21/pr-newswire-hyp...   \n",
       "2       https://www.wsj.com/articles/dont-get-distract...   \n",
       "3       https://www.reuters.com/video/2018/03/27/gsk-b...   \n",
       "4       https://www.reuters.com/article/usa-stocks/us-...   \n",
       "...                                                   ...   \n",
       "411596  http://www.reuters.com/article/2010/02/08/us-u...   \n",
       "411597  http://www.reuters.com/article/2008/01/29/us-s...   \n",
       "411598  https://uk.reuters.com/article/uk-royal-mail-o...   \n",
       "411599  https://www.cnbc.com/video/2018/01/31/china-is...   \n",
       "411600  https://www.reuters.com/article/brief-humana-r...   \n",
       "\n",
       "                                                     text  text_length  \\\n",
       "0       In the Middle East, all eyes are fixed on Syri...         6646   \n",
       "1       NEW YORK, May 21, 2018 /PRNewswire/ -- HYPR Co...         5496   \n",
       "2       Trade negotiations with China are grinding for...          582   \n",
       "3       GSK buys out Novartis in $13bln shake-up 8:48a...          534   \n",
       "4       April 18, 2018 / 6:20 PM / Updated 18 minutes ...          849   \n",
       "...                                                   ...          ...   \n",
       "411596   The Fed's purchases last year of longer-term ...         4535   \n",
       "411597   Societe Generale last week revealed that a ro...         3151   \n",
       "411598  January 18, 2018 / 7:30 AM / Updated 12 hours ...         1401   \n",
       "411599  China is a target market for Scotch Whisky 20 ...          193   \n",
       "411600   46 AM / in 12 minutes BRIEF-Humana Reports Qt...         1673   \n",
       "\n",
       "       news_medium news_type  \n",
       "0          reuters   article  \n",
       "1             cnbc       NaN  \n",
       "2              wsj  articles  \n",
       "3          reuters     video  \n",
       "4          reuters   article  \n",
       "...            ...       ...  \n",
       "411596     reuters   article  \n",
       "411597     reuters   article  \n",
       "411598  uk.reuters   article  \n",
       "411599        cnbc     video  \n",
       "411600     reuters   article  \n",
       "\n",
       "[411547 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA CLEANING \n",
    "\n",
    "\n",
    "merged_df['text_length'] = merged_df['text'].apply(lambda text: len(text))\n",
    "\n",
    "merged_df['news_medium'] = merged_df['url'].str.extract(r'https?://([^/]+)')[0].str.replace('www.', '', regex=False).str[:-4]\n",
    "\n",
    "#Standardizing dates and getting more date information from url\n",
    "\n",
    "#Turning string dates to YYYY-MM-DD HH:MM:SS Format\n",
    "merged_df['Date'] = merged_df['Date'].apply(lambda date: parser.parse(date) if pd.notna(date) else np.NaN)\n",
    "\n",
    "\n",
    "#Getting dates from URL\n",
    "\n",
    "\n",
    "url_dates = merged_df['url'].str.extract(r'/(\\d{4})[/\\-](\\d{2})[/\\-](\\d{2})/').dropna().T.apply('-'.join)\n",
    "\n",
    "merged_df['Date'] = merged_df['Date'].fillna(url_dates)\n",
    "\n",
    "\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce')\n",
    "\n",
    "merged_df['Date'] = merged_df['Date'].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "#News article types\n",
    "merged_df['news_type'] = merged_df['url'].str.extract(r'/([a-zA-Z]+)/')[0]\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34107ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reuters_df = ds_to_spark(reuters_spark, \"danidanou/Reuters_Financial_News\", 30000)\n",
    "#finnews_df = ds_to_spark(finnews_spark, \"ashraq/financial-news-articles\", 30000)\n",
    "\n",
    "# Check if successful\n",
    "#if reuters_df:\n",
    "    #print(\"Reuters dataset loaded successfully\")\n",
    "    #reuters_df.show(5)\n",
    "\n",
    "#if finnews_df:\n",
    "    #print(\"Financial News dataset loaded successfully\") \n",
    "    #finnews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e4a8b",
   "metadata": {},
   "source": [
    "Below are methods to push the data to Supabase DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "364a0ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname aws-0-us-east-2.pooler.supabase.com resolved successfully\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "hostname = \"aws-0-us-east-2.pooler.supabase.com\"\n",
    "try:\n",
    "    socket.gethostbyname(hostname)\n",
    "    print(f\"Hostname {hostname} resolved successfully\")\n",
    "except socket.gaierror:\n",
    "    print(f\"Could not resolve hostname: {hostname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea93169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Medici_roasting@19'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff26e0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cxxzifmsmlxqllnfcurt.supabase.co'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"DB_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1f13590",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"DB_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93950a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "url: str = os.getenv(\"DB_URL\")\n",
    "key: str = os.getenv(\"DB_TOKEN\")\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7afa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = (\n",
    "            supabase.table(\"pretrain_data\")\n",
    "            .insert([\n",
    "                merged_df.to_json()\n",
    "                ])\n",
    "            .execute()\n",
    "        )\n",
    "    return response\n",
    "except Execption as exception:\n",
    "    return exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230c1cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(psycopg2.OperationalError) could not translate host name \"19@aws-0-us-east-2.pooler.supabase.com\" to address: nodename nor servname provided, or not known\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3297\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3277\u001b[0m \n\u001b[1;32m   3278\u001b[0m \u001b[38;5;124;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m     fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/default.py:625\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOperationalError\u001b[0m: could not translate host name \"19@aws-0-us-east-2.pooler.supabase.com\" to address: nodename nor servname provided, or not known\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgresql://postgres.cxxzifmsmlxqllnfcurt:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msb_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m@aws-0-us-east-2.pooler.supabase.com:5432/postgres\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m conn \u001b[38;5;241m=\u001b[39m create_engine(connection, pool_pre_ping\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmerged_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpretrain_df\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/generic.py:3087\u001b[0m, in \u001b[0;36mNDFrame.to_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[38;5;124;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;124;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[0;32m-> 3087\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3088\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3090\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3093\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3098\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/sql.py:841\u001b[0m, in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame, DataFrame):\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    838\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument should be either a Series or a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    839\u001b[0m     )\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpandasSQL_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mto_sql(\n\u001b[1;32m    843\u001b[0m         frame,\n\u001b[1;32m    844\u001b[0m         name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs,\n\u001b[1;32m    854\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/sql.py:906\u001b[0m, in \u001b[0;36mpandasSQL_builder\u001b[0;34m(con, schema, need_transaction)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing URI string without sqlalchemy installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sqlalchemy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, (\u001b[38;5;28mstr\u001b[39m, sqlalchemy\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39mConnectable)):\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSQLDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_transaction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m adbc \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madbc_driver_manager.dbapi\u001b[39m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adbc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, adbc\u001b[38;5;241m.\u001b[39mConnection):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/sql.py:1636\u001b[0m, in \u001b[0;36mSQLDatabase.__init__\u001b[0;34m(self, con, schema, need_transaction)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39mcallback(con\u001b[38;5;241m.\u001b[39mdispose)\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(con, Engine):\n\u001b[0;32m-> 1636\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_transaction \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m con\u001b[38;5;241m.\u001b[39min_transaction():\n\u001b[1;32m   1638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_stack\u001b[38;5;241m.\u001b[39menter_context(con\u001b[38;5;241m.\u001b[39mbegin())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3273\u001b[0m, in \u001b[0;36mEngine.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Connection:\n\u001b[1;32m   3251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[1;32m   3252\u001b[0m \n\u001b[1;32m   3253\u001b[0m \u001b[38;5;124;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3270\u001b[0m \n\u001b[1;32m   3271\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:147\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mraw_connection()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 147\u001b[0m         \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2436\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception_noconnection\u001b[0;34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[0m\n\u001b[1;32m   2434\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:145\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbapi_connection \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect\u001b[38;5;241m.\u001b[39mloaded_dbapi\u001b[38;5;241m.\u001b[39mError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    147\u001b[0m         Connection\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception_noconnection(\n\u001b[1;32m    148\u001b[0m             err, dialect, engine\n\u001b[1;32m    149\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/base.py:3297\u001b[0m, in \u001b[0;36mEngine.raw_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[1;32m   3277\u001b[0m \n\u001b[1;32m   3278\u001b[0m \u001b[38;5;124;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:449\u001b[0m, in \u001b[0;36mPool.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PoolProxiedConnection:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:1264\u001b[0m, in \u001b[0;36m_ConnectionFairy._checkout\u001b[0;34m(cls, pool, threadconns, fairy)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_checkout\u001b[39m(\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     fairy: Optional[_ConnectionFairy] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ConnectionFairy:\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[0;32m-> 1264\u001b[0m         fairy \u001b[38;5;241m=\u001b[39m \u001b[43m_ConnectionRecord\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1267\u001b[0m             threadconns\u001b[38;5;241m.\u001b[39mcurrent \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(fairy)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:713\u001b[0m, in \u001b[0;36m_ConnectionRecord.checkout\u001b[0;34m(cls, pool)\u001b[0m\n\u001b[1;32m    711\u001b[0m     rec \u001b[38;5;241m=\u001b[39m cast(_ConnectionRecord, pool\u001b[38;5;241m.\u001b[39m_do_get())\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 713\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     dbapi_connection \u001b[38;5;241m=\u001b[39m rec\u001b[38;5;241m.\u001b[39mget_connection()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:179\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection()\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dec_overflow()\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/impl.py:177\u001b[0m, in \u001b[0;36mQueuePool._do_get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inc_overflow():\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:390\u001b[0m, in \u001b[0;36mPool._create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConnectionPoolEntry:\n\u001b[1;32m    388\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:675\u001b[0m, in \u001b[0;36m_ConnectionRecord.__init__\u001b[0;34m(self, pool, connect)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pool \u001b[38;5;241m=\u001b[39m pool\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_callback \u001b[38;5;241m=\u001b[39m deque()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:901\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m    902\u001b[0m         pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError on connect(): \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py:224\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/pool/base.py:897\u001b[0m, in \u001b[0;36m_ConnectionRecord.__connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdbapi_connection \u001b[38;5;241m=\u001b[39m connection \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    898\u001b[0m     pool\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, connection)\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/create.py:646\u001b[0m, in \u001b[0;36mcreate_engine.<locals>.connect\u001b[0;34m(connection_record)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    644\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[0;32m--> 646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sqlalchemy/engine/default.py:625\u001b[0m, in \u001b[0;36mDefaultDialect.connect\u001b[0;34m(self, *cargs, **cparams)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcargs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcparams: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DBAPIConnection:\n\u001b[1;32m    624\u001b[0m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloaded_dbapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/psycopg2/__init__.py:122\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     kwasync[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    121\u001b[0m dsn \u001b[38;5;241m=\u001b[39m _ext\u001b[38;5;241m.\u001b[39mmake_dsn(dsn, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 122\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     conn\u001b[38;5;241m.\u001b[39mcursor_factory \u001b[38;5;241m=\u001b[39m cursor_factory\n",
      "\u001b[0;31mOperationalError\u001b[0m: (psycopg2.OperationalError) could not translate host name \"19@aws-0-us-east-2.pooler.supabase.com\" to address: nodename nor servname provided, or not known\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "sb_key = os.getenv(\"SB_PASS\")\n",
    "connection = f\"postgresql://postgres.cxxzifmsmlxqllnfcurt:{sb_key}@aws-0-us-east-2.pooler.supabase.com:5432/postgres\"\n",
    "\n",
    "conn = create_engine(connection,)\n",
    "\n",
    "merged_df.to_sql('pretrain_data', con=conn, rewrite=True,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf0ac0",
   "metadata": {},
   "source": [
    "Below are methods to tokenize the merged dataset and push the data to huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd1c76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll do 3 methods the first will be to take the first 512 words of an article (if it has it), combine into a column for a dataframe\n",
    "#The second method will be to take the middle 512 words (if available) of an article and combine into a column\n",
    "#The third will be to take the first 2000 words of an article, combine into a column \n",
    "\n",
    "from pyspark.sql.functions import substring, col, expr\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "\n",
    "#Method one\n",
    "first_512_df = merged_df[merged_df['text_length'] >= 512]\n",
    "\n",
    "#Method two\n",
    "\n",
    "#Making a function to define middle of column\n",
    "middle_512_df = merged_df\n",
    "middle_512_df['text'] = merged_df['text'].apply(\n",
    "    lambda text: text[int((len(text) - 512) / 2):int(len(text) - (len(text) - 512) / 2)]\n",
    ")\n",
    "\n",
    "#Third_method\n",
    "first_4096_df = merged_df[merged_df[\"text_length\"] >= 4096]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "948ddca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbf3afe7a1f4f24933fcfd9e5f002ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/314651 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f19f06f2724947975eca4ab2ed4372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/411601 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee47a987c1e544db93602028a2563200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The third method will feed into a longform tranfsformer for pretraining\n",
    "#The second method and first method will feed into a DistilBERT for pretraining\n",
    "#We'll use a one lstm that will train on the first 512 words (benchmark, to be added later)\n",
    "\n",
    "\n",
    "#Bert tokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "lf_tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "\n",
    "datasets_pd = {\n",
    "    'first_512': first_512_df,\n",
    "    'middle_512': middle_512_df, \n",
    "    'first_4096': first_4096_df\n",
    "}\n",
    "\n",
    "    \n",
    "# Tokenize\n",
    "datasets_hf = {\n",
    "    name: Dataset.from_pandas(df) \n",
    "    for name, df in datasets_pd.items()\n",
    "}\n",
    "\n",
    "\n",
    "configs = [\n",
    "    {'name': 'first_512', 'tokenizer': bert_tokenizer, 'max_length': 512},\n",
    "    {'name': 'middle_512', 'tokenizer': bert_tokenizer, 'max_length': 512},\n",
    "    {'name': 'first_4096', 'tokenizer': lf_tokenizer, 'max_length': 4096}\n",
    "]\n",
    "\n",
    "\n",
    "tokenized_datasets = {}\n",
    "\n",
    "\n",
    "for config in configs:\n",
    "    tokenized_datasets[config['name']] = datasets_hf[config['name']].map(\n",
    "        lambda examples: config['tokenizer'](\n",
    "            examples['text'],  # adjust column name as needed\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=config['max_length'],\n",
    "            return_tensors='pt'\n",
    "        ),\n",
    "        batched=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b454c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71fb78ff9eb40969458febad2aeca16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c9cb51f8a84ffaa0d42d9e9a3ad24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/79 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ab00b973004633ad9996c42d1bb58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/79 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b7f4ec0f041e3ba798e02b54a0e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/79 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af724a0041e4454bbdffda81ea5310ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/79 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c1ecd1cb6647c981000c72d91e9587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/369 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512fbd6610fd4e5c935c7ae5bdb93cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198fd9bb92f5451b931c74c734805a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/138 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5fd16d20c5480591f6c12eb13fb389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/138 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7238fbddf4024e10b5d575deaa684916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/138 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b607a353024254babc08136026cda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2840518fba47489f913f3a2f84a7b98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783b28393ba24f978c0b0e36a430e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4364a1cdf242f2a6f6e262a958bb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e587673c94481990813df149246cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/23 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af8ea9dd5f6485e8acacb1f21d3dedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/369 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pushing tokenized datasets to huggingface\n",
    "\n",
    "for dataset in tokenized_datasets.keys():\n",
    "    tokenized_datasets[dataset].push_to_hub(f\"Czunzun/Financial_news_{dataset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
