{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292d1fac",
   "metadata": {},
   "source": [
    "We need to collect headline data for stocks. We're going to start with one stock, google class C ($GOOG). And we also need a variety of sources. The more sources the better. We can always trim the fat.\n",
    "\n",
    "yfinance will give us a good dataset for Yahoo finance data.\n",
    "\n",
    "Since we're using Python, we need to rely on websites that are builf in HTML to not make this too over;y complicated. If most of our data sources are buiit in React or are JS- heavy, we'll switch to using JS.\n",
    "\n",
    "News Sources:\n",
    "Yahoo Finance\n",
    "CNBC\n",
    "BizToc\n",
    "Reuters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f317d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d221f688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 258 links:\n"
     ]
    }
   ],
   "source": [
    "url = \"https://biztoc.com/wire\"\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "all_links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "print(f\"Found {len(all_links)} links:\")\n",
    "\n",
    "valid_urls = list(url for url in all_links if url and url.startswith(('http://', 'https://')))\n",
    "valid_urls = valid_urls[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb1106f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_valid_links(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        links = set()  # Avoid duplicates\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            href = a['href'].strip()\n",
    "            if (href and not href.startswith(('javascript:', '#', 'mailto:', 'tel:'))\n",
    "                and not any(href.endswith(ext) for ext in ('.png', '.jpg', '.pdf', '.docx'))):\n",
    "                \n",
    "                absolute_url = urljoin(url, href)\n",
    "                if urlparse(absolute_url).scheme in ('http', 'https'):  # Validate URL\n",
    "                    links.add(absolute_url)\n",
    "        return list(links)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_headline_and_text(url):\n",
    "    service = Service()  # Specify your path\n",
    "    driver = webdriver.Chrome(service=service)\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        # Wait for main content to load\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'body')))\n",
    "        \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Better title extraction (fallback to URL)\n",
    "        title = soup.title.string if soup.title else url\n",
    "        \n",
    "        # Cleaner text extraction (skip nav/footer)\n",
    "        main_content = soup.find('main') or soup.find('article') or soup.find('body')\n",
    "        text = ' '.join([p.get_text(' ', strip=True) \n",
    "                        for p in main_content.find_all(['p', 'h1', 'h2', 'h3']) \n",
    "                        if p.get_text(strip=True)])\n",
    "        \n",
    "        return title, text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None, None\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()  # Ensure driver closes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8c4d849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:46,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://theweek.com/culture-life/americas-favorite-fast-food-restaurants?ref=biztoc.com: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=137.0.7151.55)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000105314708 cxxbridge1$str$ptr + 2729312\n",
      "1   chromedriver                        0x000000010530c96c cxxbridge1$str$ptr + 2697156\n",
      "2   chromedriver                        0x0000000104e5e728 cxxbridge1$string$len + 90444\n",
      "3   chromedriver                        0x0000000104e38744 chromedriver + 132932\n",
      "4   chromedriver                        0x0000000104ecdc9c cxxbridge1$string$len + 546496\n",
      "5   chromedriver                        0x0000000104ee6be0 cxxbridge1$string$len + 648708\n",
      "6   chromedriver                        0x0000000104e99bc0 cxxbridge1$string$len + 333284\n",
      "7   chromedriver                        0x00000001052d8298 cxxbridge1$str$ptr + 2482416\n",
      "8   chromedriver                        0x00000001052db52c cxxbridge1$str$ptr + 2495364\n",
      "9   chromedriver                        0x00000001052b9ae0 cxxbridge1$str$ptr + 2357560\n",
      "10  chromedriver                        0x00000001052dbdb4 cxxbridge1$str$ptr + 2497548\n",
      "11  chromedriver                        0x00000001052aadec cxxbridge1$str$ptr + 2296900\n",
      "12  chromedriver                        0x00000001052fbc4c cxxbridge1$str$ptr + 2628260\n",
      "13  chromedriver                        0x00000001052fbdd8 cxxbridge1$str$ptr + 2628656\n",
      "14  chromedriver                        0x000000010530c5b8 cxxbridge1$str$ptr + 2696208\n",
      "15  libsystem_pthread.dylib             0x000000019f856c0c _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000019f851b80 thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:26<01:57, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://thehill.com/homenews/house/5320723-congressional-republicans-tax-spending-cut/?ref=biztoc.com: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=137.0.7151.55)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000104ea8708 cxxbridge1$str$ptr + 2729312\n",
      "1   chromedriver                        0x0000000104ea096c cxxbridge1$str$ptr + 2697156\n",
      "2   chromedriver                        0x00000001049f2728 cxxbridge1$string$len + 90444\n",
      "3   chromedriver                        0x00000001049cc744 chromedriver + 132932\n",
      "4   chromedriver                        0x0000000104a61c9c cxxbridge1$string$len + 546496\n",
      "5   chromedriver                        0x0000000104a7abe0 cxxbridge1$string$len + 648708\n",
      "6   chromedriver                        0x0000000104a2dbc0 cxxbridge1$string$len + 333284\n",
      "7   chromedriver                        0x0000000104e6c298 cxxbridge1$str$ptr + 2482416\n",
      "8   chromedriver                        0x0000000104e6f52c cxxbridge1$str$ptr + 2495364\n",
      "9   chromedriver                        0x0000000104e4dae0 cxxbridge1$str$ptr + 2357560\n",
      "10  chromedriver                        0x0000000104e6fdb4 cxxbridge1$str$ptr + 2497548\n",
      "11  chromedriver                        0x0000000104e3edec cxxbridge1$str$ptr + 2296900\n",
      "12  chromedriver                        0x0000000104e8fc4c cxxbridge1$str$ptr + 2628260\n",
      "13  chromedriver                        0x0000000104e8fdd8 cxxbridge1$str$ptr + 2628656\n",
      "14  chromedriver                        0x0000000104ea05b8 cxxbridge1$str$ptr + 2696208\n",
      "15  libsystem_pthread.dylib             0x000000019f856c0c _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000019f851b80 thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:10<00:39,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping https://www.fiercebiotech.com/biotech/eli-lilly-lands-next-gen-pain-asset-siteone-therapeutics-acquisition-worth-1b?ref=biztoc.com: Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=137.0.7151.55)\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ccc708 cxxbridge1$str$ptr + 2729312\n",
      "1   chromedriver                        0x0000000102cc496c cxxbridge1$str$ptr + 2697156\n",
      "2   chromedriver                        0x0000000102816728 cxxbridge1$string$len + 90444\n",
      "3   chromedriver                        0x00000001027f0744 chromedriver + 132932\n",
      "4   chromedriver                        0x0000000102885c9c cxxbridge1$string$len + 546496\n",
      "5   chromedriver                        0x000000010289ebe0 cxxbridge1$string$len + 648708\n",
      "6   chromedriver                        0x0000000102851bc0 cxxbridge1$string$len + 333284\n",
      "7   chromedriver                        0x0000000102c90298 cxxbridge1$str$ptr + 2482416\n",
      "8   chromedriver                        0x0000000102c9352c cxxbridge1$str$ptr + 2495364\n",
      "9   chromedriver                        0x0000000102c71ae0 cxxbridge1$str$ptr + 2357560\n",
      "10  chromedriver                        0x0000000102c93db4 cxxbridge1$str$ptr + 2497548\n",
      "11  chromedriver                        0x0000000102c62dec cxxbridge1$str$ptr + 2296900\n",
      "12  chromedriver                        0x0000000102cb3c4c cxxbridge1$str$ptr + 2628260\n",
      "13  chromedriver                        0x0000000102cb3dd8 cxxbridge1$str$ptr + 2628656\n",
      "14  chromedriver                        0x0000000102cc45b8 cxxbridge1$str$ptr + 2696208\n",
      "15  libsystem_pthread.dylib             0x000000019f856c0c _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000019f851b80 thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:53<00:00, 11.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # Progress bar\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "MAX_LINKS = 10  # Prevent runaway scraping\n",
    "output_data = []\n",
    "\n",
    "# Scrape with progress tracking\n",
    "for link in tqdm(valid_urls[:MAX_LINKS]):\n",
    "    try:\n",
    "        title, text = get_headline_and_text(link)\n",
    "        if title and text:  # Only store valid data\n",
    "            output_data.append({\n",
    "                'url': link,\n",
    "                'headline': title,\n",
    "                'body': text,\n",
    "                'date': datetime.now().strftime('%Y-%m-%d')  # Placeholder\n",
    "            })\n",
    "        time.sleep(random.uniform(1, 5))  # Be polite\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {link} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert to DataFrame once\n",
    "df = pd.DataFrame(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef199ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zerohedge.com/medical/rogan-rodger...</td>\n",
       "      <td>Rogan &amp; Rodgers Unleash Big Pharma's Worst Nig...</td>\n",
       "      <td>Rogan &amp; Rodgers Unleash Big Pharma's Worst Nig...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nytimes.com/2025/05/27/us/politics...</td>\n",
       "      <td>Republicans Urge Trump to Put New Sanctions on...</td>\n",
       "      <td>Russia-Ukraine War Advertisement Supported by ...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.benzinga.com/insights/news/25/05/4...</td>\n",
       "      <td>$1000 Invested In Marsh &amp; McLennan Cos 10 Year...</td>\n",
       "      <td>$1000 Invested In Marsh &amp; McLennan Cos 10 Year...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.nytimes.com/2025/05/27/us/politics...</td>\n",
       "      <td>Judge Strikes Down Trump Order Targeting Wilme...</td>\n",
       "      <td>Trump Administration Advertisement Supported b...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.cnbc.com/2025/05/27/circle-ipo-has...</td>\n",
       "      <td>Circle IPO has peculiar Facebook-like characte...</td>\n",
       "      <td>Circle IPO has peculiar Facebook-like characte...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.theglobeandmail.com/business/comme...</td>\n",
       "      <td>A Throne Speech fit for a king. But where’s th...</td>\n",
       "      <td>A Throne Speech fit for a king. But where’s th...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://thehill.com/business/5320681-tesla-sha...</td>\n",
       "      <td>Tesla stock recovers as Musk shifts focus back...</td>\n",
       "      <td>Tesla shares rise after Musk says he’s back at...</td>\n",
       "      <td>2025-05-27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zerohedge.com/medical/rogan-rodger...   \n",
       "1  https://www.nytimes.com/2025/05/27/us/politics...   \n",
       "2  https://www.benzinga.com/insights/news/25/05/4...   \n",
       "3  https://www.nytimes.com/2025/05/27/us/politics...   \n",
       "4  https://www.cnbc.com/2025/05/27/circle-ipo-has...   \n",
       "5  https://www.theglobeandmail.com/business/comme...   \n",
       "6  https://thehill.com/business/5320681-tesla-sha...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Rogan & Rodgers Unleash Big Pharma's Worst Nig...   \n",
       "1  Republicans Urge Trump to Put New Sanctions on...   \n",
       "2  $1000 Invested In Marsh & McLennan Cos 10 Year...   \n",
       "3  Judge Strikes Down Trump Order Targeting Wilme...   \n",
       "4  Circle IPO has peculiar Facebook-like characte...   \n",
       "5  A Throne Speech fit for a king. But where’s th...   \n",
       "6  Tesla stock recovers as Musk shifts focus back...   \n",
       "\n",
       "                                                body        date  \n",
       "0  Rogan & Rodgers Unleash Big Pharma's Worst Nig...  2025-05-27  \n",
       "1  Russia-Ukraine War Advertisement Supported by ...  2025-05-27  \n",
       "2  $1000 Invested In Marsh & McLennan Cos 10 Year...  2025-05-27  \n",
       "3  Trump Administration Advertisement Supported b...  2025-05-27  \n",
       "4  Circle IPO has peculiar Facebook-like characte...  2025-05-27  \n",
       "5  A Throne Speech fit for a king. But where’s th...  2025-05-27  \n",
       "6  Tesla shares rise after Musk says he’s back at...  2025-05-27  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
