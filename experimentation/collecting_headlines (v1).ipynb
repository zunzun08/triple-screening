{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292d1fac",
   "metadata": {},
   "source": [
    "We need to collect headline data for stocks. We're going to start with one stock, google class C ($GOOG). And we also need a variety of sources. The more sources the better. We can always trim the fat.\n",
    "\n",
    "yfinance will give us a good dataset for Yahoo finance data.\n",
    "\n",
    "Since we're using Python, we need to rely on websites that are builf in HTML to not make this too over;y complicated. If most of our data sources are buiit in React or are JS- heavy, we'll switch to using JS.\n",
    "\n",
    "News Sources:\n",
    "Yahoo Finance\n",
    "CNBC\n",
    "BizToc\n",
    "Reuters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd5fb1",
   "metadata": {},
   "source": [
    "Update (06/13/2025):\n",
    "\n",
    "After developing a decent solution using python, the problem I'm facing are:\n",
    "1. A majority of the big websites like Bloomberg or NYT have paywalls. This isn't a real problem and it doesn't mean the website can't be scrapped because the website typically has a 'soft paywall' where the paywall can be turned off and the news can be scrapped.\n",
    "2. Most modern websites, especially for the large news websites use React. So, the best solution here would be to use Javascript instead of Python to scrape these sites. We'll move over to collecting_headlines (v2) to continue the goal.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
